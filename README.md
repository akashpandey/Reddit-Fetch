
# Reddit Saved Posts Fetcher

## üìå Overview

This script fetches your **saved Reddit posts and comments** using the Reddit API with OAuth authentication. It supports exporting saved posts in **JSON** and **HTML bookmarks**, making it easy to archive and integrate with tools like **Linkwarden** and **Hoarder**.

### **Key Features**

- ‚úÖ **Incremental Fetching** ‚Üí Retrieves only new saved posts using `before` (incremental) or `after` (full fetch).
- ‚úÖ **JSON-First Approach** ‚Üí Data is always stored in JSON first, ensuring correct ordering.
- ‚úÖ **Multiple Export Formats** ‚Üí Supports **JSON and HTML bookmarks**.
- ‚úÖ **Python Library Support** ‚Üí Can be used as a function call in external programs.
- ‚úÖ **Docker Support** ‚Üí Easily deploy and run the fetcher in a containerized environment.
- ‚úÖ **Force Fetch Mode** ‚Üí Optionally re-fetch all saved posts using `--force-fetch`.

---

## üîß Installation & Setup

### **1Ô∏è‚É£ Clone the Repository**

```bash
git clone https://github.com/akashpandey/Reddit-Fetch.git
cd Reddit-Fetch
```

### **2Ô∏è‚É£ Install as a Python Package**

```bash
pip install -e .
```

### **3Ô∏è‚É£ Configure Reddit API Credentials**

1. Go to [Reddit Apps](https://www.reddit.com/prefs/apps) and create a **Web App**.
2. Set the **Redirect URI** to `http://localhost:8080`.
3. Copy the **Client ID** and **Client Secret**.

### **4Ô∏è‚É£ Create `.env` File**

```ini
CLIENT_ID=your_client_id
CLIENT_SECRET=your_client_secret
REDIRECT_URI=http://localhost:8080
USER_AGENT=YourRedditApp/1.0 (by /u/your_username)
REDDIT_USERNAME=your_reddit_username
FETCH_INTERVAL=3600
FORCE_FETCH=false
```

---

## üîë Authentication & Token Handling

Run the following command to authenticate and generate `tokens.json`:

```bash
python generate_tokens.py
```

### **Handling Tokens in a Headless Server**

1. Run `generate_tokens.py` on a **system with a browser**.
2. Copy the `tokens.json` file to the **server or Docker volume**.
3. **For Docker users**, place `tokens.json` inside the `/data/` directory.

Tokens are **automatically refreshed** as needed.

---

## üöÄ Running the Script

### **Using CLI After Package Installation**

```bash
reddit-fetcher
```

- The CLI will prompt for format selection (`json` or `html`) and whether to force fetch.
- Runs interactively without requiring additional arguments.

### **Fetching New Saved Posts (Non-Interactive Mode)**

#### ‚úÖ **Incremental Fetch (Recommended)**

```bash
python main.py --format json
```

```bash
python main.py --format html
```

- Uses **`before`** for **incremental fetching** (fetches only new posts).

#### ‚úÖ **Force Fetch (Re-Fetch Everything)**

```bash
python main.py --format json --force-fetch
```

```bash
python main.py --format html --force-fetch
```

- Uses **`after`** for **full fetch** (fetches all saved posts from the beginning).

---

## üìÇ Using as a Python Library

This script can be used as a **function call inside another Python program**.

### ‚úÖ **Expected Return Type**

- Returns **a list of dictionaries**, where each entry contains:

```json
[
    {
        "title": "Post Title",
        "url": "https://reddit.com/r/example",
        "subreddit": "example",
        "created_utc": 1700000000,
        "fullname": "t3_xxxxxx"
    }
]
```

### ‚úÖ **Sample External Program Usage**

```python
from reddit_fetch.api import fetch_saved_posts

# Fetch saved posts as JSON
data = fetch_saved_posts(format="json", force_fetch=False)
print(f"Fetched {len(data)} saved posts")
```

---

## üê≥ Running in Docker

### **1Ô∏è‚É£ Build the Docker Image**

```bash
docker build -t reddit-fetcher .
```

### **2Ô∏è‚É£ Run the Container**

```bash
docker run --rm -e OUTPUT_FORMAT=json -e FORCE_FETCH=false -e FETCH_INTERVAL=3600 -v $(pwd)/data:/data reddit-fetcher
```

- JSON will be saved in `data/saved_posts.json`.
- HTML will be saved in `data/saved_posts.html` if `OUTPUT_FORMAT=html`.
- `FETCH_INTERVAL` controls how frequently the script runs in Docker.
- `FORCE_FETCH` can be set to `true` to fetch all saved posts from scratch.

### **3Ô∏è‚É£ Using Docker Compose**

If you prefer using `docker-compose`, create a `docker-compose.yml` file:

```yaml
version: '3.8'
services:
  reddit-fetcher:
    image: reddit-fetcher
    container_name: reddit-fetcher
    environment:
      - OUTPUT_FORMAT=json
      - FORCE_FETCH=false
      - FETCH_INTERVAL=3600
    volumes:
      - ./data:/data
    restart: unless-stopped
```

Run the container using:

```bash
docker-compose up -d
```

### **4Ô∏è‚É£ Handling `tokens.json` in Docker**

- If using Docker, **place `tokens.json` inside the `/data/` directory** before starting the container.
- Example:

```bash
cp tokens.json data/
```

---

## üîç Troubleshooting

### **1Ô∏è‚É£ Token Errors**

- If `tokens.json` is missing, **run `generate_tokens.py` again**.
- Ensure **Reddit API credentials** are correctly set in `.env`.
- If using Docker, **copy `tokens.json` to `/data/` before running the container**.

### **2Ô∏è‚É£ Fetching Issues**

- Ensure the correct **Reddit username** is set in `.env`.
- Check if you've hit **Reddit API rate limits**.

---

## üîç Future Enhancements

- **Advanced Filtering** (by subreddit, date, etc.).
- **RSS Feed Generation** for easier integration.
- **Direct API Integration with Linkwarden**.

---

üí° **Contributions & feedback are welcome!** üöÄ
